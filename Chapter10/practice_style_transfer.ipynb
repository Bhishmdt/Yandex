{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_practice_style_transfer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYvnVzA2DmIu"
      },
      "source": [
        "### Week 10 - text style transfer\n",
        "\n",
        "Hello, sitzen class A.412C!\n",
        "\n",
        "Based on your browser search history, we conclude that you have an above average skill in natural language processing. In our benevolence, we give you a chance to contribute your skills to upholding the happiest society in the universe. Are you up to the task?\n",
        "\n",
        "As you know, our most recent breakthrough was replacing 97% restaurant workers with BFGHQBERT+++ autonomous food dispensers.\n",
        "\n",
        "Yet a some radical elements failed to recognize the greater good that we brought them. They mistakenly voice their ignorant opinions about our new INGSOC-approved restaurants, brining dangerous doubt to the minds of our loyal citzens.\n",
        "\n",
        "Surely you cannot tolerate such infidelity! Our loyal citzens demand that you rectify their mistake. _You must build a model that will automatically improve their ignorant thoughts and replace them with the thoughts they should actually have._\n",
        "\n",
        "Attached below are the INGSOC-approved datasets for ignorant and correct thoughts. The scientific terminology is for wrong opinions and correct opinions is \"negative\" and \"positive\", respectively.\n",
        "\n",
        "Respond within 7 days or you will lose 3.7629 citzenship points.\n",
        "\n",
        "![img](https://ih1.redbubble.net/image.1254830934.9884/poster,504x498,f8f8f8-pad,400x240,f8f8f8.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z63QypDjVmIe"
      },
      "source": [
        "!pip install -q transformers\n",
        "!wget -q https://github.com/shentianxiao/language-style-transfer/raw/master/data/yelp/sentiment.train.0 -O train_negative\n",
        "!wget -q https://github.com/shentianxiao/language-style-transfer/raw/master/data/yelp/sentiment.train.1 -O train_positive\n",
        "!wget -q https://github.com/shentianxiao/language-style-transfer/raw/master/data/yelp/sentiment.dev.0 -O dev_negative\n",
        "!wget -q https://github.com/shentianxiao/language-style-transfer/raw/master/data/yelp/sentiment.dev.1 -O dev_positive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQADoMFcU5cU",
        "outputId": "595165d2-6d61-4096-b7bb-03a617f3cacd"
      },
      "source": [
        "!head -n 5 ./dev_positive\n",
        "!echo\n",
        "!head -n 5 ./dev_negative"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "staff behind the deli counter were super nice and efficient !\n",
            "love this place !\n",
            "the staff are always very nice and helpful .\n",
            "the new yorker was amazing .\n",
            "very ny style italian deli .\n",
            "\n",
            "ok never going back to this place again .\n",
            "easter day nothing open , heard about this place figured it would ok .\n",
            "the host that walked us to the table and left without a word .\n",
            "it just gets worse .\n",
            "the food tasted awful .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MTzCt4i6BE-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "if device == 'cpu':\n",
        "    print(\"Fine-tuning BERT without an accelerator is not party-approved.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGhzg7qKKdqX"
      },
      "source": [
        "### Part 1: Masked language model\n",
        "\n",
        "Attached below you can find the INGSOC-compliant training code that fine-tunes a BERT model for Masked Language Modeling.\n",
        "\n",
        "You shall use this model to generate positive replacements for negative tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhhZG7YMVihR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e9b8631-e085-4233-ab97-3337def39357"
      },
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_mlm_positive = BertForMaskedLM.from_pretrained('bert-base-uncased', return_dict=True).to(device).train(True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Ir_RGWBWMF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "11f9d2d9-7a33-4397-a7e5-68c81937ea4b"
      },
      "source": [
        "from transformers import LineByLineTextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "print(\"Preparing the training data...\")\n",
        "dataset = LineByLineTextDataset(\n",
        "    file_path=\"./train_positive\", tokenizer=tokenizer, block_size=128)\n",
        "\n",
        "print(\"Dataset ready!\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=bert_mlm_positive, train_dataset=dataset, \n",
        "    data_collator=DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15),\n",
        "    args=TrainingArguments(\n",
        "        output_dir=\"./bert_mlm_positive\", overwrite_output_dir=True,\n",
        "        num_train_epochs=1, per_device_train_batch_size=32,\n",
        "        save_steps=1_000, save_total_limit=2),\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:128: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Preparing the training data...\n",
            "Dataset ready!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='8354' max='8354' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8354/8354 24:29, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.446300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.166000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.130200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.072800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.077600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.048100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.056300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.043300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.983100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.946500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.962400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.949300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.945500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.941200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8354, training_loss=1.0444445090628367, metrics={'train_runtime': 1469.2923, 'train_samples_per_second': 5.686, 'total_flos': 3284256698954208, 'epoch': 1.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO0jC8_7OWrq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "06007fd0-8894-41ad-df5c-bdc1b5f5861f"
      },
      "source": [
        "# <Build and train a MLM for incorrect opinions>\n",
        "\n",
        "bert_mlm_negative = BertForMaskedLM.from_pretrained('bert-base-uncased', return_dict=True).to(device).train(True)\n",
        "print(\"Preparing the training data...\")\n",
        "dataset = LineByLineTextDataset(\n",
        "    file_path=\"./train_negative\", tokenizer=tokenizer, block_size=128)\n",
        "\n",
        "print(\"Dataset ready!\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=bert_mlm_negative, train_dataset=dataset, \n",
        "    data_collator=DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15),\n",
        "    args=TrainingArguments(\n",
        "        output_dir=\"./bert_mlm_negative\", overwrite_output_dir=True,\n",
        "        num_train_epochs=1, per_device_train_batch_size=32,\n",
        "        save_steps=1_000, save_total_limit=2),\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:128: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Preparing the training data...\n",
            "Dataset ready!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='5525' max='5525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5525/5525 17:11, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.499500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.244700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.185100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.152500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.133400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.109500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.080500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.096800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.082700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.057200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>1.051000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5525, training_loss=1.1531272045843202, metrics={'train_runtime': 1032.1273, 'train_samples_per_second': 5.353, 'total_flos': 2399611589197200, 'epoch': 1.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_IQohMhO63b"
      },
      "source": [
        "### Part 2: Replace tokens\n",
        "\n",
        "You can now use the two masked language models to align user opinions. You can do so with the following steps:\n",
        "\n",
        "1. Find tokens where the ratio $(P_{positive}(x) + \\epsilon) / (P_{negative}(x) + \\epsilon)$ is the smallest\n",
        "2. Replace those tokens with one of $k$ most likely tokens according to $P_{positive}(x)$.\n",
        "3. Rinse, repeat\n",
        "\n",
        "You can find the full procedure at https://arxiv.org/abs/2010.01054"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAL8pSER7WtA"
      },
      "source": [
        "best_positive_checkpoint = './bert_mlm_positive/checkpoint-8000'\n",
        "best_negative_checkpoint = './bert_mlm_negative/checkpoint-5000'\n",
        "bert_mlm_positive = BertForMaskedLM.from_pretrained(best_positive_checkpoint, return_dict=True).to(device)\n",
        "bert_mlm_negative = BertForMaskedLM.from_pretrained(best_negative_checkpoint, return_dict=True).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzgw0fnz-s3e"
      },
      "source": [
        "bert_mlm_positive.train(False)\n",
        "bert_mlm_negative.train(False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fbSwmbx_hiO"
      },
      "source": [
        "sentence = \"great wings and decent drinks but the wait staff is horrible !\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekdjdmDA_nT7"
      },
      "source": [
        "batch = tokenizer([f\"great wings and decent drinks but the wait staff is horrible !\"],\n",
        "                  padding=True, truncation=True, return_tensors=\"pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgGF_dVY_zlO",
        "outputId": "f57312f0-e1f7-4a07-a763-fe9568916f4e"
      },
      "source": [
        "batch.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2307,  4777,  1998, 11519,  8974,  2021,  1996,  3524,  3095,\n",
              "          2003,  9202,   999,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nHXGqFyEBSl8",
        "outputId": "ddc1bdb8-b537-4ef5-f1f6-98fa2e66d459"
      },
      "source": [
        "tokenizer.decode(batch['input_ids'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] great wings and decent drinks but the wait staff is horrible! [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQqBzsAV_rjs",
        "outputId": "03923b7f-8e6d-4ccb-c2e6-025d4c1e9981"
      },
      "source": [
        "bert_mlm_positive(**batch)['logits'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 14, 30522])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C85u1R1KDXm_"
      },
      "source": [
        "mask_position = batch['input_ids'][0].tolist().index(103)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yCDSSVuDjd7",
        "outputId": "f4aeef3e-805f-419c-d9c0-1a001ad13755"
      },
      "source": [
        "mask_position"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkHhu9fcBr3s"
      },
      "source": [
        "logits = bert_mlm_positive(**batch)['logits'][0, 11].detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmZfH0yvCQE7",
        "outputId": "4f06940e-2a1b-490f-8e78-4e3a384eed5d"
      },
      "source": [
        "np.argsort(-logits)[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2307, 12476,  6429, 10392,  5151])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cG9E4XHCcY4"
      },
      "source": [
        "id_to_vocab = {i: token for token, i in tokenizer.vocab.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbVJUENkC7fr",
        "outputId": "083d88c3-f220-4779-8959-137c097d77b8"
      },
      "source": [
        "for index in np.argsort(-logits)[:5]:\n",
        "  print(id_to_vocab[index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "great\n",
            "awesome\n",
            "amazing\n",
            "fantastic\n",
            "outstanding\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTIuM3TXPce8"
      },
      "source": [
        "lsm = nn.Softmax(dim=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVfJC5_kRskk"
      },
      "source": [
        "def get_replacements(sentence: str, num_tokens, k_best, epsilon=1e-3):\n",
        "  \"\"\"\n",
        "  - split the sentence into tokens using the INGSOC-approved BERT tokenizer\n",
        "  - find :num_tokens: tokens with the highest ratio (see above)\n",
        "  - replace them with :k_best: words according to bert_mlm_positive\n",
        "  :return: a list of all possible strings (up to k_best * num_tokens)\n",
        "  \"\"\"\n",
        "  batch = tokenizer([sentence], padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "  logits_p = bert_mlm_positive(**batch)['logits'].detach().cpu()\n",
        "  probs_p = torch.max(lsm(logits_p), dim=2).values.squeeze(0).numpy()\n",
        "  logits_n = bert_mlm_negative(**batch)['logits'].detach().cpu()\n",
        "  probs_n = torch.max(lsm(logits_n), dim=2).values.squeeze(0).numpy()\n",
        "  ratio = (probs_p + epsilon) / (probs_n + epsilon)\n",
        "  ratio = ratio[1:-1]\n",
        "  n = np.argsort(ratio)\n",
        "  result = []\n",
        "  for i in n[:num_tokens]:\n",
        "    logits = logits_p[0, i + 1]\n",
        "    for index in np.argsort(-logits)[:k_best].numpy():\n",
        "      ids = batch['input_ids'][0].detach().cpu().numpy()\n",
        "      ids = ids[1:-1]\n",
        "      ids[i] = index\n",
        "      s = tokenizer.decode(ids)\n",
        "      result.append(s)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT7rmowuMw3x",
        "outputId": "f5abc5c1-bc45-48ba-fee8-6eecdbfa3000"
      },
      "source": [
        "get_replacements(\"great wings and decent drinks but the wait staff is horrible !\",\n",
        "                 num_tokens=1, k_best=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['great wings and decent drinks but the wait staff is great!',\n",
              " 'great wings and decent drinks but the wait staff is awesome!',\n",
              " 'great wings and decent drinks but the wait staff is amazing!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RJptvlOTfs4"
      },
      "source": [
        "dev_data = list(open('./dev_negative'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2UlAc6QToKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2864d08e-2278-48a6-fa4e-f45a590eaa6b"
      },
      "source": [
        "dev_data[500:505]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wrong !\\n',\n",
              " \"i 'm sure she wo n't issue a refund because - surprise !\\n\",\n",
              " \"nothing special and the drinks are n't cheap .\\n\",\n",
              " 'great wings and decent drinks but the wait staff is horrible !\\n',\n",
              " 'the tables are all saved by people crowded around the two tvs .\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXEuVoTmTSV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b82e901-a627-4e79-f4bc-2769ec458ae2"
      },
      "source": [
        "get_replacements(\"great wings and decent drinks but the wait staff is horrible !\",\n",
        "                 num_tokens=1, k_best=2)\n",
        "# >>> [\"great wings and decent drinks but the wait staff is great !\", \"great wings and decent drinks but the wait staff is awesome !\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['great wings and decent drinks but the wait staff is great!',\n",
              " 'great wings and decent drinks but the wait staff is awesome!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZvy3rECWMZB"
      },
      "source": [
        "__Final task__ - build a procedure that iteratively applies replacements, demonstrate the effectiveness of your approach with at least 10 examples to satisfy INGSOC.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO4-HGVucn56"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIpWUOkvUAdi"
      },
      "source": [
        "samples = random.sample(dev_data, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZvACl7qc4c6",
        "outputId": "5ad431c7-a88a-4d2d-c42d-a5938da58c55"
      },
      "source": [
        "for sample in samples:\n",
        "  print(sample)\n",
        "  print(get_replacements(sample, 1, 2))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no melon ... strawberries and bananas .\n",
            "\n",
            "['no melon... strawberries and bananas.', 'no melon... strawberry and bananas.']\n",
            "\n",
            "despite my complaining , i continue to go back , every week ... why ?\n",
            "\n",
            "['despite my complaining, i continue to go back, every week... why?', 'spite my complaining, i continue to go back, every week... why?']\n",
            "\n",
            "the televisions are over _num_ years old , tube televisions with horrible viewing .\n",
            "\n",
            "['the televisions are over _ num _ years old, tube televisions with great viewing.', 'the televisions are over _ num _ years old, tube televisions with horrible viewing.']\n",
            "\n",
            "can you say worst customer service ever ?\n",
            "\n",
            "['can you say worst customer service ever?', 'can you say best customer service ever?']\n",
            "\n",
            "what the hell is that about ?\n",
            "\n",
            "['what the hell is that about?', 'what the hell is that like?']\n",
            "\n",
            "moreover , the salads are noticeably smaller with less fresh greens .\n",
            "\n",
            "['moreover, the salads are much smaller with less fresh greens.', 'moreover, the salads are slightly smaller with less fresh greens.']\n",
            "\n",
            "ruins the meal .\n",
            "\n",
            "['enjoyed the meal.', 'enjoy the meal.']\n",
            "\n",
            "i called immediately and the owner denied it was washed instead of dry cleaned .\n",
            "\n",
            "['i called immediately and the owner denied it was washed instead of dry cleaned.', 'i called immediately and the owner said it was washed instead of dry cleaned.']\n",
            "\n",
            "the .\n",
            "\n",
            "['delicious.', 'amazing.']\n",
            "\n",
            "this was unacceptable !\n",
            "\n",
            "['this was great!', 'this was amazing!']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
