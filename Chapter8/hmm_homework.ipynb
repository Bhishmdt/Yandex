{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "8_hmm-homework.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twSarcMj-JO_"
      },
      "source": [
        "**Hidden Markov models for cracking codes**\n",
        "\n",
        "In this homework will use an HMM work to solve some  substitution ciphers. \n",
        "\n",
        "You are given some short encrypted texts from various English and Russian authors. Each was encoded using a different character substitution cipher. You need to identify the author of each. Plaintext data is provided with examples of each of the authors.\n",
        "\n",
        "\n",
        "This homework is worth **15 points** and is due by **2st Dec. 03:00**, please submit the results of the **TASK 5** (a list of files and names of the author/work) to Anytask in the following format: \n",
        "\n",
        "```\n",
        "filename\\tauthor\\tfirst_3_lines_of_decoded_text\n",
        "```\n",
        "    \n",
        "where 'filename' is the encrypted file from \"encrypted/\" and the name of the 'author' from \"plaintext/\" \n",
        "\n",
        "Using an HMM you will not be able to decode the text perfectly, but you'll see that it's often readable and you should be able to automatically identify the author by matching it against lines in the plaintext files.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "BMG4xzYeFgp6",
        "outputId": "29103653-9d01-4dc1-efa2-8e28603e7b7a"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-343a4331-a5e0-4994-baa8-df316f4cadfd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-343a4331-a5e0-4994-baa8-df316f4cadfd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving english.txt to english.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23o_T0BP-JPH"
      },
      "source": [
        "# Utilities for loading data from file and converting characters to integers and back.\n",
        "import numpy as np\n",
        "    \n",
        "def get_char_to_int_mapping(path):\n",
        "    # Load data from path and get mapping from characters to integers and back.\n",
        "    characters = set()\n",
        "    for line in open(path):\n",
        "        characters.update(set([c for c in line.strip()]))\n",
        "    char_to_int_mapping = dict([(char, i) for i, char in enumerate(sorted(list(characters)))])\n",
        "    int_to_char_mapping = [char for char, i in sorted(char_to_int_mapping.items(), key=lambda x: x[1])]\n",
        "    return char_to_int_mapping, int_to_char_mapping\n",
        "\n",
        "def load_sequences(path, char_to_int_mapping):\n",
        "    # Load data from path and map to integers using mapping.\n",
        "    return [[char_to_int_mapping[c] for c in line.strip()] for line in open(path)]\n",
        "\n",
        "def estimate_markov_model_from_sequences(sequences, num_states):\n",
        "    # Estimate a Markov model based on the sequences (integers) provided.\n",
        "\n",
        "    # pi[i] = Pr(s_0 = i)\n",
        "    pi_counts = np.zeros(num_states)\n",
        "\n",
        "    # A[i, j] = Pr(s_t = j | s_{t-1} = i)\n",
        "    A_counts = np.zeros((num_states, num_states))\n",
        "\n",
        "    for n, sequence in enumerate(sequences):\n",
        "        assert False, \"Collect counts for pi and A and return parameter estimates.\"\n",
        "    \n",
        "    # return pi, A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzsdfOET-JPK"
      },
      "source": [
        "**TASK 1**: Make the following block run by completing the method 'estimate_markov_model_from_sequences' above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBoGGAZr-JPK"
      },
      "source": [
        "# Some data to use.\n",
        "plaintext = '/content/english.txt'\n",
        "# plaintext = 'plaintext/shakespeare.txt'\n",
        "# plaintext = 'plaintext/russian.txt'\n",
        "\n",
        "ciphertext = '/content/encrypted-2.txt' # short sequences in english\n",
        "# ciphertext = 'encrypted/99_encrypted.txt' # longer sequences in russian\n",
        "\n",
        "# load a character to integer mapping and reverse                                                                                                         \n",
        "char_to_int_mapping, int_to_char_mapping = get_char_to_int_mapping(plaintext)\n",
        "\n",
        "# load sequences as ints                                                                                                                                  \n",
        "plaintext_sequences = load_sequences(plaintext, char_to_int_mapping)\n",
        "encrypted_sequences = load_sequences(ciphertext, char_to_int_mapping)\n",
        "\n",
        "# estimate a markov model over characters                                                                                                                 \n",
        "pi, A = estimate_markov_model_from_sequences(plaintext_sequences, len(char_to_int_mapping))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38Jd5Xcc-JPK"
      },
      "source": [
        "Below is a mostly implemented HMM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lXPMjhC-JPL"
      },
      "source": [
        "class HMM():\n",
        "\n",
        "    def __init__(self, observations_to_char_mapping={}, states_to_char_mapping={}):\n",
        "        # Determine number of states and observation space. \n",
        "        self.num_states = len(states_to_char_mapping)\n",
        "        self.num_outputs = len(observations_to_char_mapping)\n",
        "        self.states_to_char_mapping = states_to_char_mapping\n",
        "        self.observations_to_char_mapping = observations_to_char_mapping\n",
        "       \n",
        "        # Random initialization\n",
        "        self.pi = np.random.rand(self.num_states)\n",
        "        self.pi /= np.sum(self.pi)\n",
        "        self.A = np.random.rand(self.num_states, self.num_states)\n",
        "        self.A /= np.sum(self.A, 1, keepdims=True)\n",
        "        self.B = np.random.rand(self.num_states, self.num_outputs)\n",
        "        self.B /= np.sum(self.B, 1, keepdims=True) \n",
        "        \n",
        "    def estimate_with_em(self, sequences, parameters={}, epsilon=0.001, max_iters=100):\n",
        "        # Estimates all parameters not provided in 'parameters' based on 'sequences'.\n",
        "        self.fixed_pi = 'pi' in parameters\n",
        "        if self.fixed_pi:\n",
        "            self.pi = parameters['pi']\n",
        "        self.fixed_A = 'A' in parameters\n",
        "        if self.fixed_A:\n",
        "            self.A = parameters['A']\n",
        "        self.fixed_B = 'B' in parameters\n",
        "        if self.fixed_B:\n",
        "            self.B = parameters['B']\n",
        "    \n",
        "        previous_llh = None\n",
        "        for iter in range(max_iters):\n",
        "            # Infer expected counts.\n",
        "            pi_counts, A_counts, B_counts, log_likelihood = self.e_step(sequences)\n",
        "\n",
        "            # Update parameters based on counts.\n",
        "            self.m_step(pi_counts, A_counts, B_counts)\n",
        "\n",
        "            # Output some sequences for debugging.\n",
        "            self.output(sequences[:10])\n",
        "\n",
        "            # Log likelihood should be increasing\n",
        "            print('iteration %d; log likelihood %.4f' % (iter, log_likelihood))\n",
        "            if previous_llh:\n",
        "                assert log_likelihood >= previous_llh\n",
        "                if log_likelihood - previous_llh < epsilon:\n",
        "                    break\n",
        "            previous_llh = log_likelihood\n",
        "\n",
        "\n",
        "    def e_step(self, sequences):\n",
        "        # Reset counters of statistics\n",
        "        pi_counts = np.zeros_like(self.pi)\n",
        "        A_counts = np.zeros_like(self.A) \n",
        "        B_counts = np.zeros_like(self.B) \n",
        "        total_log_likelihood = 0.0\n",
        "\n",
        "        for sequence in sequences:\n",
        "            # Run Forward-Backward dynamic program\n",
        "            alpha, beta, gamma, xi, log_likelihood = self.forward_backward(sequence)\n",
        "  \n",
        "            # Accumulate statistics.\n",
        "            pi_counts += gamma[:, 0]\n",
        "            A_counts += xi\n",
        "            for t, x in enumerate(sequence):\n",
        "                B_counts[:, x] += gamma[:, t]\n",
        "            \n",
        "            total_log_likelihood += log_likelihood\n",
        "\n",
        "        return pi_counts, A_counts, B_counts, total_log_likelihood\n",
        "\n",
        "    def m_step(self, pi_counts, A_counts, B_counts):\n",
        "        if not self.fixed_pi:\n",
        "            self.pi = pi_counts / np.sum(pi_counts)\n",
        "        if not self.fixed_A:\n",
        "            self.A = A_counts / np.sum(A_counts, 1, keepdims=True)\n",
        "        if not self.fixed_B:\n",
        "            self.B = B_counts / np.sum(B_counts, 1, keepdims=True)\n",
        "        \n",
        "    def max_posterior_decode(self, sequence):\n",
        "        _, _, gamma, _, log_likelihood = self.forward_backward(sequence)\n",
        "        return np.argmax(gamma, 0)\n",
        "        \n",
        "    def forward_backward(self, sequence):\n",
        "        # alpha[i][t] = p(x_1, ..., x_t, z_t = i)\n",
        "        alpha = self.forward(sequence)\n",
        "        \n",
        "        # beta[i][t] = p(x_t+1, ..., x_T|z_t = i)\n",
        "        beta = self.backward(sequence)\n",
        "\n",
        "        # gamma[i][t] = p(z_t = i|x_1, ..., x_T)\n",
        "        gamma = (alpha * beta) / np.sum(alpha * beta, 0)\n",
        "\n",
        "        # xi[i][j] = p(z_t = i, z_{t+1} = j|x_1, ..., x_T)\n",
        "        xi = np.zeros_like(self.A)\n",
        "        for t in range(1, len(sequence)-1):\n",
        "            this_xi = np.zeros_like(self.A)\n",
        "            for i in range(self.num_states):\n",
        "                for j in range(self.num_states):\n",
        "                    this_xi[i, j] += alpha[i, t] * self.A[i, j] * beta[j, t+1] * self.B[j, sequence[t+1]]        \n",
        "            xi += this_xi / np.sum(this_xi)\n",
        "                \n",
        "        return alpha, beta, gamma, xi, np.log(np.sum(alpha[:, len(sequence)-1]))\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        # alpha[i][t] = p(x_1, ..., x_t, z_t = i)\n",
        "        alpha = np.zeros((len(self.pi), len(sequence)))\n",
        "        assert False, \"Implement forward recursion\"\n",
        "        return alpha \n",
        "    \n",
        "    def backward(self, sequence):\n",
        "        # beta[i][t] = p(x_t+1, ..., x_T|z_t = i)\n",
        "        beta = np.zeros((len(self.pi), len(sequence)))\n",
        "        assert False, \"Implement backwards recursion to compute betas.\"\n",
        "        return beta\n",
        "\n",
        "    def output(self, sequences):\n",
        "        # Output some decoded states. \n",
        "        for i, sequence in enumerate(sequences):\n",
        "            observations = [self.observations_to_char_mapping[x] for x in sequence]                \n",
        "            map_states = [self.states_to_char_mapping[x] for x in self.max_posterior_decode(sequence)]\n",
        "            print('(states):       %s\\n(observations): %s' % (''.join(map_states), ''.join(observations)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyJtVkPo-JPO"
      },
      "source": [
        "**TASK 2**: Implement the assertions in 'forward' and 'backward' methods on the HMM class so that the following block passes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs5B862Y-JPR"
      },
      "source": [
        "# Since it's a substitution cipher we assume hidden states and observations have same alphabet.\n",
        "state_to_char_mapping = int_to_char_mapping\n",
        "observation_to_char_mapping = int_to_char_mapping\n",
        "\n",
        "# Initialize a HMM with the correct state/output spaces.\n",
        "hmm = HMM(observation_to_char_mapping, state_to_char_mapping)\n",
        "\n",
        "# Estimate the parameters and decode the encrypted sequences.\n",
        "hmm.estimate_with_em(encrypted_sequences[:100], parameters={})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrgKqYKQ-JPR"
      },
      "source": [
        "**TASK 3**: Some of the encrypted sequences are quite long. Try decoding some from 'encrypted/encrypted-5.txt' (note these are in Russian)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD5BAGP6-JPS"
      },
      "source": [
        "**TASK 4**: Make your implementation of forward and backward more efficient by removing all but the outermost for-loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LZXyVFj-JPS"
      },
      "source": [
        "**TASK 5**: Try to classify the author of each text by decoding some of it and matching it against the samples provided for each author."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frMtiljj-JPS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
